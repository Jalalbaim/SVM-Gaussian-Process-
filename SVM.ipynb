{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on MNIST dataset \n",
    "@author BAIM Mohamed Jalal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import csv\n",
    "from libsvm.svmutil import svm_train, svm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_x_train = '../data/X_train.csv'\n",
    "path_x_test = '../data/X_test.csv'\n",
    "path_y_train = '../data/y_train.csv'\n",
    "path_y_test = '../data/y_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: kernel func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "X_train shape: (5000, 784)\n",
      "y_train shape: 5000\n",
      "X_test shape: (2500, 784)\n",
      "y_test shape: 2500\n"
     ]
    }
   ],
   "source": [
    "def load_data(X_train_path, y_train_path, X_test_path, y_test_path):\n",
    "    X_train = np.zeros((0, 784))\n",
    "    y_train = []\n",
    "    X_test = np.zeros((0, 784))\n",
    "    y_test = []\n",
    "\n",
    "    with open(X_train_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            X_train = np.vstack([X_train, np.array(row).astype(float)])\n",
    "    with open(y_train_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            y_train.append(int(row[0]))\n",
    "    with open(X_test_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            X_test = np.vstack([X_test, np.array(row).astype(float)])\n",
    "    with open(y_test_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            y_test.append(int(row[0]))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(path_x_train, path_y_train, path_x_test, path_y_test)\n",
    "\n",
    "print('Data loaded')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', len(y_train))\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with linear kernel\n",
      "Accuracy = 95.08% (2377/2500) (classification)\n",
      "\n",
      "Training with polynomial kernel\n",
      "Accuracy = 34.68% (867/2500) (classification)\n",
      "\n",
      "Training with rbf kernel\n",
      "Accuracy = 95.32% (2383/2500) (classification)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train using different kernels\n",
    "KERNEL = ['linear', 'polynomial', 'rbf']\n",
    "for i, kernel_name in enumerate(KERNEL):\n",
    "    print('Training with', kernel_name, 'kernel')\n",
    "    model = svm_train(y_train, X_train, '-t {} -q'.format(i))\n",
    "    p_label, p_acc, p_val = svm_predict(y_test, X_test, model)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hyperparameters(Y, X, hyperparameters, optimal_accuracy, optimal_parameters):\n",
    "    print(\"Evaluating hyperparameters:\", hyperparameters)\n",
    "    cv_accuracy = svm_train(Y, X, hyperparameters)\n",
    "    \n",
    "    if cv_accuracy > optimal_accuracy:\n",
    "        optimal_accuracy = cv_accuracy\n",
    "        optimal_parameters = hyperparameters\n",
    "    \n",
    "    return optimal_accuracy, optimal_parameters\n",
    "\n",
    "\n",
    "def grid_search(X, Y, kernel):\n",
    "    cost = [0.01, 0.1, 1, 10]\n",
    "\n",
    "    optimal_accuracy = 0\n",
    "    optimal_parameters = ''\n",
    "\n",
    "    if kernel == 'linear':\n",
    "        print('-'*50)\n",
    "        print('Linear Kernel')\n",
    "        print('-'*50)\n",
    "        for c in cost:\n",
    "            config = f'-s 0 -t 0 -c {c} -v 3 -q'\n",
    "            optimal_accuracy, optimal_parameters = evaluate_hyperparameters(Y, X, config, optimal_accuracy, optimal_parameters)\n",
    "            print('-'*50)\n",
    "    elif kernel == 'polynomial':\n",
    "        print('-'*50)\n",
    "        print('Polynomial Kernel')\n",
    "        print('-'*50)\n",
    "        degree = [2, 3, 4]\n",
    "        gammas = [0.01, 0.1, 1]\n",
    "        for c in cost:\n",
    "            for d in degree:\n",
    "                for g in gammas:\n",
    "                    config = f'-s 0 -t 1 -c {c} -d {d} -g {g} -v 3 -q'\n",
    "                    optimal_accuracy, optimal_parameters = evaluate_hyperparameters(Y, X, config, optimal_accuracy, optimal_parameters)\n",
    "                    print('-'*50)\n",
    "\n",
    "    elif kernel == 'RBF':\n",
    "        print('-'*50)\n",
    "        print('RBF Kernel')\n",
    "        print('-'*50)\n",
    "        gammas = [0.01, 0.1, 1]\n",
    "        for c in cost:\n",
    "            for g in gammas:\n",
    "                config = f'-s 0 -t 2 -c {c} -g {g} -v 3 -q'\n",
    "                optimal_accuracy, optimal_parameters = evaluate_hyperparameters(Y, X, config, optimal_accuracy, optimal_parameters)\n",
    "                print('-'*50)\n",
    "\n",
    "    return optimal_accuracy, optimal_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Linear Kernel\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 0 -c 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 96.74%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 0 -c 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.86%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 0 -c 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.2%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 0 -c 10 -v 3 -q\n",
      "Cross Validation Accuracy = 96.28%\n",
      "--------------------------------------------------\n",
      "Optimal parameters: -s 0 -t 0 -c 0.1 -v 3 -q\n",
      "Optimal accuracy: 96.86\n"
     ]
    }
   ],
   "source": [
    "optimal_accuracy, optimal_parameters = grid_search(X_train, y_train, 'linear')\n",
    "print('Optimal parameters:', optimal_parameters)\n",
    "print('Optimal accuracy:', optimal_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Polynomial Kernel\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 2 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 77.78%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 2 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.5%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 2 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.88%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 3 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 58.7%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 3 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.44%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 3 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.46%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 4 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 45.54%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 4 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.58%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.01 -d 4 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.22%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 2 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 94.38%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 2 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.82%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 2 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.74%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 3 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 89.1%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 3 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.32%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 3 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.58%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 4 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 79.42%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 4 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.14%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 0.1 -d 4 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.44%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 2 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 97.48%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 2 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.88%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 2 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.94%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 3 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 96.18%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 3 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.48%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 3 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.48%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 4 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 92.48%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 4 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.44%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 1 -d 4 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.24%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 2 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 97.88%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 2 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 98.06%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 2 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 98.08%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 3 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 97.68%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 3 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.36%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 3 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 97.36%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 4 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 95.8%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 4 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.28%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 1 -c 10 -d 4 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.02%\n",
      "--------------------------------------------------\n",
      "Optimal parameters: -s 0 -t 1 -c 10 -d 2 -g 1 -v 3 -q\n",
      "Optimal accuracy: 98.08\n"
     ]
    }
   ],
   "source": [
    "optimal_accuracy2, optimal_parameters2 = grid_search(X_train, y_train, 'polynomial')\n",
    "print('Optimal parameters:', optimal_parameters2)\n",
    "print('Optimal accuracy:', optimal_accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "RBF Kernel\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 0.01 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 91.84%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 0.01 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 50.1%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 0.01 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 21.5%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 0.1 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 96.2%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 0.1 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 53.44%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 0.1 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 20.94%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 1 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 97.62%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 1 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 91.34%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 1 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 29.68%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 10 -g 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 97.9%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 10 -g 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 91.5%\n",
      "--------------------------------------------------\n",
      "Evaluating hyperparameters: -s 0 -t 2 -c 10 -g 1 -v 3 -q\n",
      "Cross Validation Accuracy = 31.46%\n",
      "--------------------------------------------------\n",
      "Optimal parameters: -s 0 -t 2 -c 10 -g 0.01 -v 3 -q\n",
      "Optimal accuracy: 97.89999999999999\n"
     ]
    }
   ],
   "source": [
    "optimal_accuracy3, optimal_parameters3 = grid_search(X_train, y_train, 'RBF')\n",
    "print('Optimal parameters:', optimal_parameters3)\n",
    "print('Optimal accuracy:', optimal_accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 \n",
    "linear + RBF kernels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Kernel Hyperparameter Tuning\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=0.01, gamma=0.01\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 96.9%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=0.01, gamma=0.1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 96.9%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=0.01, gamma=1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "Cross Validation Accuracy = 96.72%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=0.1, gamma=0.01\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.9%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=0.1, gamma=0.1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.82%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=0.1, gamma=1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 0.1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.88%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=1, gamma=0.01\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.18%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=1, gamma=0.1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.26%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=1, gamma=1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 1 -v 3 -q\n",
      "Cross Validation Accuracy = 96.48%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=10, gamma=0.01\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 10 -v 3 -q\n",
      "Cross Validation Accuracy = 96.44%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=10, gamma=0.1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 10 -v 3 -q\n",
      "Cross Validation Accuracy = 96.42%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Testing combined kernel with C=10, gamma=1\n",
      "Evaluating hyperparameters: -s 0 -t 4 -c 10 -v 3 -q\n",
      "Cross Validation Accuracy = 96.28%\n",
      "Current best accuracy: 96.89999999999999% with parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "--------------------------------------------------\n",
      "Best configuration found\n",
      "**************************************************\n",
      "Optimal parameters: -s 0 -t 4 -c 0.01 -v 3 -q\n",
      "Optimal accuracy: 96.89999999999999%\n"
     ]
    }
   ],
   "source": [
    "def linear_kernel(X1, X2):\n",
    "    \"\"\"Compute the linear kernel.\"\"\"\n",
    "    return np.dot(X1, X2.T)\n",
    "\n",
    "def rbf_kernel(X1, X2, gamma):\n",
    "    \"\"\"Compute the RBF kernel.\"\"\"\n",
    "    sq_dist = np.sum(X1**2, axis=1).reshape(-1, 1) + np.sum(X2**2, axis=1) - 2 * np.dot(X1, X2.T)\n",
    "    return np.exp(-gamma * sq_dist)\n",
    "\n",
    "def combined_kernel(X1, X2, gamma):\n",
    "    \"\"\"\n",
    "    Combine linear and RBF kernels:\n",
    "    K_combined = alpha * K_linear + beta * K_RBF\n",
    "    \"\"\"\n",
    "    K_linear = linear_kernel(X1, X2)\n",
    "    K_rbf = rbf_kernel(X1, X2, gamma)\n",
    "    return K_linear + K_rbf\n",
    "\n",
    "def create_precomputed_kernel_matrix(X, X_ref, kernel_func, *kernel_params):\n",
    "    \"\"\"\n",
    "    Create a precomputed kernel matrix for use with libsvm.\n",
    "    \"\"\"\n",
    "    kernel_matrix = kernel_func(X, X_ref, *kernel_params)\n",
    "    m = kernel_matrix.shape[0]\n",
    "    precomputed = np.zeros((m, m + 1))\n",
    "    precomputed[:, 1:] = kernel_matrix\n",
    "    precomputed[:, 0] = np.arange(1, m + 1)\n",
    "    return precomputed\n",
    "\n",
    "# Hyperparameter tuning with combined kernel\n",
    "print('Combined Kernel Hyperparameter Tuning')\n",
    "print('-' * 50)\n",
    "\n",
    "gammas = [0.01, 0.1, 1]\n",
    "cost = [0.01, 0.1, 1, 10]\n",
    "optimal_accuracy = 0\n",
    "optimal_parameters = None\n",
    "\n",
    "for c in cost:\n",
    "    for g in gammas:\n",
    "        print(f\"Testing combined kernel with C={c}, gamma={g}\")\n",
    "        train_kernel = create_precomputed_kernel_matrix(X_train, X_train, combined_kernel, g)\n",
    "        config = f'-s 0 -t 4 -c {c} -v 3 -q'\n",
    "        optimal_accuracy, optimal_parameters = evaluate_hyperparameters(\n",
    "            y_train, train_kernel, config, optimal_accuracy, optimal_parameters\n",
    "        )\n",
    "        print(f\"Current best accuracy: {optimal_accuracy}% with parameters: {optimal_parameters}\")\n",
    "        print('-' * 50)\n",
    "        \n",
    "print('Best configuration found')\n",
    "print('*' * 50)\n",
    "print(f'Optimal parameters: {optimal_parameters}')\n",
    "print(f'Optimal accuracy: {optimal_accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
